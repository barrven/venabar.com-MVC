-: You could have the prettiest, highest resolution monitor in the world, but without the right graphics card to push it you're not gonna get anything on your screen. So, what I wanna talk about this episode is just what is a graphics card, and what we should expect. Now, I've got an older graphics card right here in front of me. And you know what? There's a big old heat sink on here. Don't try this at home kids. Ah, I just ripped a heat sink off. It's okay. He's a trained professional. So, what I want you to look at here first of all, is this fellow right here. This is the GPU, or the graphics processing unit. Back in the old days, in order to make something appear on a screen, you had to use some kind of RAM that kept track of what is in every single pixel electronically. And then you would push that out to the monitor itself. And now that works, and it's known as frame buffering. However, in today's world, we have these very smart processors on our video cards. So instead of talking to our video card and saying, "This pixel's red, this pixel's red, this pixel's red this pixel's red, this pixel's blue, this pixel," this kind of a thing over a million times, what we do instead is we go to our GPU and say, "Put a circle right here." Or, "Here's an icon that I'm using a lot, keep that in another part of your memory," 'cause GPUs also have their own memory. Take a look right here. So, on this particular one, I've got these four, these are actually DDR2 RAM chips and they do nothing more than actually store what's on the monitor at any given moment. So if I had some super-duper magnetic ability to read these chips, I could actually see my image being stored on there. Now, what will take place is, many, many times per second, hopefully a minimum of 60 times a second, although it can get a lot faster than that, we have a little scanner. And the thing is just scanning back and forth, and every time it has one of these cycles, it shoots new data out to the monitor, and the monitor resets all the pixels forever to the new image. So, you might be just moving a icon across your desktop but your computer is setting that image up a minimum of 60 times a second. Alright. So we're gonna have a certain type of GPU and we're gonna have a certain type of RAM. People get really into the types of GPUs and often have more difficulty picking their video card because of the GPU than they do the CPU on their computer itself. Right now we have two big competitors. We have NVIDIA Corporation, and then we have ATI which is now a part of AMD. There's actually a third person. We don't talk about them very much, but they're very popular and it's called Intel. Intel sells a lot of GPUs that are really designed more to work on the motherboard itself. So, we've got all of these cards, but I wanna show you something else else really quick. What we have here is a type of video connection called HDMI. We'll talk about him in a second. But what's important is that this is soldered into the motherboard itself. And that's because the vast majority of CPUs these days have built-in GPUs. In fact, AMD, Intel's big competitor, they'll sell you a CPU, but if they sell you A CPU with a built-in GPU, they call it a APU. Got all those letters together, kids? Don't worry, I don't either, and it's not on the test. What is important is that there has to be this extra chip on there that has the brains to take commands from the CPU, and then the CPU doesn't have to sit here and address every little pixel, he just talks to the GPU, and the GPU handles all that individual addressing. We've been that way for a long, long time, and we're gonna continue to go that way going forward. Alright, so, we've got the GPU and we have some type of RAM that's actually on the card itself. Oh, by the way, on today's systems, it's not uncommon to see eight gigabytes of RAM on the board itself. And that's not only to resolve the screen, but a lot of times it'll be resolving the next screen, getting it ready to go. They'll save some memory, like all of the pixels or icons, instead of having to redraw them through logic, they'll keep a copy of it in hidden parts of their memory and then when it's time to draw that icon again, they just go boom, and it's automatically there. So, lots of cool stuff like that. But, you can have the greatest graphics card in the world and you can have the greatest monitor, but you gotta connect them at some point, and that's where our different types of connections come into play. So the first thing I wanna show you is right here. This is the granddaddy of all connectors. This is called VGA. VGA stands for Video Graphics Array, and it's been around since the 1980s and you still see it out there a little bit. It's distinct in that it's going to have 15 pins on three rows. And, although there are some exceptions, it's almost always a blue connector. That's not a law or standard, it's just a common thing that we see done all the time. The problem with VGA, if you wanna call it a problem, is that it's an analog signal. So what would happen is, if I had a VGA LCD, which, remember, it needs a digital signal, it would come through VGA into the monitor, the monitor would then have to convert that signal into digital, and then update all the individual pixels. And it worked fine, but it seemed to be kind of a wasted step. So what we began to see, many, many years ago, and we're still enjoying that today, is digital signals. And we're gonna start with the first popular digital signal, DVI. So, this particular card has two DVI connectors on them. Now, DVI being the first digital connector that was out there, there was a lot of challenge because a lot of people still had analog LCD panels, so they didn't wanna leave these folks in the dust. So what they did was actually something very clever, and I need you to look right here on the far right-hand of each one of those. So, you see it looks like a cross with four little dots in there. What you're looking at is an analog signal. It's basically a VGA signal, but they've kind of cut down on the pins a little bit. The whole idea behind this is that, if you've got an old VGA monitor, you can still use one of these video cards. However, you're gonna have to use some kind of adapter, like, so, look at this adapter right here. So, on one end, it's DVI, but on the other end, it's VGA. So you think, oh here's a DVI to VGA connector. That means I can take any DVI signal and make it VGA. Well you can't. What you also have is something that looks like this. Now, take a look at this DVI connector right here. You notice on the far right-hand side there's just a little dash there, there's no cross with the four little dots. Here, lemme see if I can put another one there for comparison's sake. So what you're looking at here is, these white ones are what we call DVI-I. That means they can do both digital and analog. This one we see here is called DVI-D. It is just digital. You can plug that DVI to VGA connector all week in that DVI-D one and nothing's gonna happen. In fact, it won't plug in. That's what that cross and the minus are for. It'll prevent you from actually plugging in the connector. So, the other nice part about DVI is that DVI came out in two versions, single-link and dual-link. The original idea behind dual-link is that you could take one DVI connector in your card and run two monitors. However, over time, monitor resolutions kept getting bigger and bigger and we see dual-link now designed to handle large high resolution monitors. To show you all of 'em, let me just put this up on the screen real quick. So here we've got the single-link, which are distinct, they've got that little space, and then we have the dual-link where we have all of those pins. And then you can tell the DVI-I from the DVI-D, whether it's just a little minus sign or a cross with the four pins in it. DVI was a pretty amazing interface and had a long run as the most popular video interface we saw running between our graphics cards and our monitors. Now, there was one problem with DVI, and that was, you still had to go through configuration to make it work. And at this point in the game, people are doing a lot more consumer electronics. People are wanting to have DVRs, and they wanna plug in a TV, and they wanna watch movies, and there was a lot of challenge about digital rights management, people basically wanting to protect their movies and music and such. And the industry came out with something called HDMI, which is High-Definition Multimedia Interface. Now, HDMI is still extremely popular. Lemme see, I should have a HDMI connection right here. So, HDMI is pretty impressive. HDMI is actually more than just for video. It also does sound, and it also can do some pretty interesting things with digital rights management as well. So, HDMI's been around for a while. At this point, I just wanna make sure we're comfortable with connectors. So, here's an HDMI connector right here. So, this is what we call regular HDMI. And right next to it I'm gonna put a mini HDMI. I have one of these on my tablet that I still use today. HDMI was and still is incredibly popular, and it's got some real benefits. For example, with HDMI, you can plug your video card into the monitor, and let's say that monitor has speakers, it will automatically start playing out to those speakers if you want it to. So, when it comes to automatic configuration, especially for home theater stuff, HDMI is still very, very popular. Now, there's nothing wrong with HDMI, but for some people, they want a real dedicated connector for their video, and that's where DisplayPort comes in. So, I've got some serious, this is a very, very serious video card I have here. And if we take a look on this, you're gonna see I've got some pretty serious connections. So we still got this DVI, forget him. And on the far right, you'll actually see that's an HDMI connection. Forget him. Do you see these three connectors right here? That, my friends, is DisplayPort. DisplayPort is extremely popular and often considered a competitor to HDMI. Now, there's a couple of different types of DisplayPort. The two I want you to be aware of are right here. So, this is regular DisplayPort, and there on the right is Mini DisplayPort. I use a Microsoft Surface laptop and this cable is precious to me. Now, what we start to see with a lot of cards is where they will put lots of different types of connectors in here. Let's take a look at this big fancy card one more time, and I want you to wrap your head around the idea that we have so many different ports on here. So I've got a DVI, I've got one HDMI, and I have three DisplayPorts. So why do we do that? Well, multiple monitors is one thing, and we cover that in other episodes. But, the other thing that comes into play is flexibility. So for a lot of people, they might buy a monitor that only has HDMI, this card works. Or they might have a monitor that, well, heaven forbid it's an old one, that only has DVI, this card will work. The only thing you have to be careful about with these cards is, a lot of times, they're going to have a default port. So you plug this in, you get it running, and you plug it in, and all of a sudden nothing's coming out there. There may not be anything wrong with the card, it's just expecting to go out from one particular port by default. Later, when we talk about video cards, I'll show you how to deal with stuff like that. So, that's our video card, A.K.A. our graphic card, interchangeable terms. These are the guys that push our monitors and make those beautiful screens. So, make sure you're comfortable with the connections. Make sure you can recognize HDMI from VGA, from all of these different fellas. And remember, the GPU and RAM, they're always gonna be on the video card, because he really needs them.